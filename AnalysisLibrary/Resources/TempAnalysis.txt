import os
import numpy as np
from math import pi, sqrt
import openseespy.opensees as ops

def run_analysis(GM_dt, GM_npts, TS_List, EDP_specs, model_params):

    stories = model_params["NumberOfStories"]
    node_tags = list(range(stories + 1))
    height = ops.nodeCoord(node_tags[-1], 3) - ops.nodeCoord(node_tags[0], 3)

    # define parameters for dynamic analysis
    dt = GM_dt          # time increment for analysis

    GMX = TS_List[0]    # list of GM accelerations in X direction
    GMY = TS_List[1]    # list of GM accelerations in Y direction

    driftLimit = 0.20   # interstory drift limit indicating collapse
    tol = 1.e-02        # tolerance criteria to check for convergence
    maxiter = 40        # max number of iterations to check
    subSteps = 2        # number of subdivisions in cases of ill convergence

    # pad shorter record with zeros (free vibration) such that two horizontal records are the same length
    nsteps = max(len(GMX), len(GMY))
    for GM in [GMX, GMY]:
        if len(GM) < nsteps:
            diff = nsteps - len(GM)
            GM.extend(np.zeros(diff))

    # initialize dictionary of envelope EDPs
    envelopeDict = {}
    for edp in EDP_specs:
        envelopeDict[edp] = {}
        for loc in EDP_specs[edp]:
            envelopeDict[edp][loc] = np.zeros(len(EDP_specs[edp][loc])).tolist()
    #print(envelopeDict)

    # initialize dictionary of time history EDPs
    time_analysis = np.zeros(nsteps * 5)
    acc_history = {}
    for floor in range(stories+1):
        acc_history.update({floor: { 1: time_analysis.copy(),
                                     2: time_analysis.copy()}})

    ops.wipeAnalysis()

    ops.constraints('Transformation')       # handles boundary conditions based on transformation equation method
    ops.numberer('RCM')                     # renumber dof's to minimize band-width (optimization)
    ops.system('UmfPack')                   # constructs sparse system of equations using UmfPack solver
    ops.test('NormDispIncr', tol, maxiter)  # tests for convergence using norm of left-hand side of matrix equation
    ops.algorithm('NewtonLineSearch')       # use Newton's solution algorithm: updates tangent stiffness at every iteration
    ops.integrator('Newmark', 0.5, 0.25)    # Newmark average acceleration method for numerical integration
    ops.analysis('Transient')               # define type of analysis: time-dependent

    # initialize variables
    maxDiv = 1024
    minDiv = subSteps
    step = 0
    ok = 0
    breaker = 0
    count = 0

    while step < nsteps and ok == 0 and breaker == 0:
        step = step + 1  # take 1 step
        ok = 2
        div = minDiv
        length = maxDiv
        while div <= maxDiv and length > 0 and breaker == 0:
            stepSize = dt / div
            # perform analysis for one increment; will return 0 if no convergence issues
            ok = ops.analyze(1, stepSize)
            if ok == 0:
                count = count + 1
                length = length - maxDiv / div

                floor = 1

                while floor <= stories:

                    # check if drift limits are satisfied
                    # check X direction drifts (direction 1)
                    drift_x = abs(ops.nodeDisp(node_tags[1], 1) -
                                  ops.nodeDisp(node_tags[0], 1)) / height
                    if drift_x >= driftLimit:
                        breaker = 1

                    # check Y direction drifts (direction 2)
                    drift_y = abs(ops.nodeDisp(node_tags[1], 2) -
                                  ops.nodeDisp(node_tags[0], 2)) / height
                    if drift_y >= driftLimit:
                        breaker = 1

                    # save parameter values in recording dictionaries at every step
                    time_analysis[count] = time_analysis[count - 1] + stepSize

                    envelopeDict['PID'][floor][0] = max(drift_x,
                                                    envelopeDict['PID'][floor][0])
                    envelopeDict['PID'][floor][1] = max(drift_y,
                                                    envelopeDict['PID'][floor][1])

                    floor = floor + 1

                for floor in range(stories+1):
                    for dof in [1, 2]:
                        acc_history[floor][dof][count] = ops.nodeAccel(
                            node_tags[floor], dof)

            else:
                div = div * 2
                print("Number of increments increased to ", str(div))

        # end analysis once drift limit has been reached
        if breaker == 1:
            ok = 1
            print("Collapse drift has been reached")

    print("Number of analysis steps completed: {}".format(count))

    # remove extra zeros from the end of the time history
    time_analysis = time_analysis[1:count + 1]

    # generate time array from recording
    time_record = np.linspace(0, nsteps * dt, num=nsteps, endpoint=False)

    # remove extra zeros from accel time history, add GM to obtain absolute a
    # acceleration, and record envelope value
    GMX_interp = np.interp(time_analysis, time_record, GMX)
    GMY_interp = np.interp(time_analysis, time_record, GMY)
    for floor in range(0, stories+1):
        # X direction
        envelopeDict['PFA'][floor][0] = max(abs(np.asarray(
            acc_history[floor][1][1:count + 1]) + GMX_interp))
        # Y direction
        envelopeDict['PFA'][floor][1] = max(abs(np.asarray(
            acc_history[floor][2][1:count + 1]) + GMY_interp))

    return envelopeDict


